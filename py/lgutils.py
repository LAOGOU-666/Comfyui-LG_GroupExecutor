from server import PromptServer
import os
import json
import threading
import time
import uuid
import asyncio
from aiohttp import web
import execution
import nodes

CATEGORY_TYPE = "ğŸˆLAOGOU/Group"

# ============ åå°æ‰§è¡Œè¾…åŠ©å‡½æ•° ============

def is_output_node(node_type):
    """é€šè¿‡æ£€æŸ¥èŠ‚ç‚¹ç±»å®šä¹‰åˆ¤æ–­æ˜¯å¦ä¸ºè¾“å‡ºèŠ‚ç‚¹"""
    try:
        if node_type in nodes.NODE_CLASS_MAPPINGS:
            node_class = nodes.NODE_CLASS_MAPPINGS[node_type]
            return getattr(node_class, "OUTPUT_NODE", False)
    except Exception as e:
        print(f"[GroupExecutor] æ£€æŸ¥è¾“å‡ºèŠ‚ç‚¹å¤±è´¥ {node_type}: {e}")
    return False

def is_node_in_group(node, group):
    """åˆ¤æ–­èŠ‚ç‚¹æ˜¯å¦åœ¨ç»„çš„è¾¹ç•Œæ¡†å†…ï¼ˆä½¿ç”¨é‡å æ£€æµ‹ï¼‰"""
    try:
        node_pos = node.get("pos", [0, 0])
        node_size = node.get("size", [140, 80])
        
        # èŠ‚ç‚¹è¾¹ç•Œæ¡†
        node_x1 = node_pos[0]
        node_y1 = node_pos[1]
        node_x2 = node_pos[0] + node_size[0]
        node_y2 = node_pos[1] + node_size[1]
        
        # ç»„è¾¹ç•Œæ¡† [x, y, width, height]
        group_bounding = group.get("bounding", [0, 0, 0, 0])
        group_x1 = group_bounding[0]
        group_y1 = group_bounding[1]
        group_x2 = group_bounding[0] + group_bounding[2]
        group_y2 = group_bounding[1] + group_bounding[3]
        
        # æ£€æŸ¥æ˜¯å¦é‡å ï¼ˆLiteGraph çš„é‡å é€»è¾‘ï¼‰
        return not (node_x2 < group_x1 or 
                   node_x1 > group_x2 or 
                   node_y2 < group_y1 or 
                   node_y1 > group_y2)
    except Exception as e:
        print(f"[GroupExecutor] æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦åœ¨ç»„å†…å¤±è´¥: {e}")
        return False

def build_prompt_for_nodes(workflow, output_node_ids):
    """ä»è¾“å‡ºèŠ‚ç‚¹åå‘æ„å»ºåŒ…å«æ‰€æœ‰ä¾èµ–çš„ prompt"""
    try:
        nodes_list = workflow.get("nodes", [])
        links_list = workflow.get("links", [])
        
        # æ„å»ºèŠ‚ç‚¹æ˜ å°„
        node_map = {n["id"]: n for n in nodes_list}
        
        # æ„å»ºè¾“å…¥è¿æ¥æ˜ å°„
        input_connections = {}
        for link in links_list:
            # link æ ¼å¼: [link_id, source_node, source_output, target_node, target_input, type]
            if len(link) >= 6:
                target_node = link[3]
                if target_node not in input_connections:
                    input_connections[target_node] = []
                input_connections[target_node].append({
                    "input_index": link[4],
                    "source_node": link[1],
                    "source_output": link[2]
                })
        
        # é€’å½’æ”¶é›†ä¾èµ–èŠ‚ç‚¹
        required_nodes = set()
        
        def collect_dependencies(node_id):
            if node_id in required_nodes:
                return
            if node_id not in node_map:
                return
            required_nodes.add(node_id)
            
            # é€’å½’æ”¶é›†è¾“å…¥èŠ‚ç‚¹
            if node_id in input_connections:
                for conn in input_connections[node_id]:
                    collect_dependencies(conn["source_node"])
        
        # ä»æ‰€æœ‰è¾“å‡ºèŠ‚ç‚¹å¼€å§‹æ”¶é›†
        for output_id in output_node_ids:
            collect_dependencies(output_id)
        
        # æ„å»º prompt
        prompt = {}
        for node_id in required_nodes:
            node = node_map[node_id]
            node_inputs = {}
            
            # å¤„ç†è¿æ¥è¾“å…¥
            if node_id in input_connections:
                for conn in input_connections[node_id]:
                    # æ‰¾åˆ°è¾“å…¥åç§°
                    node_input_list = node.get("inputs", [])
                    if conn["input_index"] < len(node_input_list):
                        input_name = node_input_list[conn["input_index"]]["name"]
                        node_inputs[input_name] = [str(conn["source_node"]), conn["source_output"]]
            
            # å¤„ç† widget å€¼
            widgets_values = node.get("widgets_values", [])
            if widgets_values:
                # è·å–èŠ‚ç‚¹ç±»çš„è¾“å…¥å®šä¹‰
                node_type = node["type"]
                if node_type in nodes.NODE_CLASS_MAPPINGS:
                    node_class = nodes.NODE_CLASS_MAPPINGS[node_type]
                    if hasattr(node_class, "INPUT_TYPES"):
                        try:
                            try:
                                input_types_result = node_class.INPUT_TYPES()
                            except:
                                # æœ‰äº›èŠ‚ç‚¹çš„ INPUT_TYPES éœ€è¦å‚æ•°
                                input_types_result = {}
                            
                            required_inputs = input_types_result.get("required", {})
                            optional_inputs = input_types_result.get("optional", {})
                            
                            # æ”¶é›†æ‰€æœ‰è¾“å…¥å®šä¹‰ï¼ˆæŒ‰é¡ºåºï¼‰
                            all_inputs = {}
                            all_inputs.update(required_inputs)
                            all_inputs.update(optional_inputs)
                            
                            # å°† widget å€¼æ˜ å°„åˆ°å‚æ•°å
                            widget_index = 0
                            for param_name, param_def in all_inputs.items():
                                if param_name not in node_inputs:  # åªå¤„ç†æœªè¿æ¥çš„è¾“å…¥
                                    if widget_index < len(widgets_values):
                                        value = widgets_values[widget_index]
                                        node_inputs[param_name] = value
                                        widget_index += 1
                                        
                                        # å¤„ç† control_after_generateï¼ˆé¢å¤–çš„ widgetï¼‰
                                        # param_def æ ¼å¼: ("TYPE", {config}) æˆ– ("TYPE",)
                                        if isinstance(param_def, (list, tuple)) and len(param_def) > 1:
                                            param_config = param_def[1]
                                            if isinstance(param_config, dict):
                                                if param_config.get("control_after_generate", False):
                                                    # è·³è¿‡ control_after_generate widgetï¼ˆåœ¨ widgets_values ä¸­å ä¸€ä¸ªä½ç½®ï¼‰
                                                    widget_index += 1
                        except Exception as widget_error:
                            print(f"[GroupExecutor] å¤„ç†èŠ‚ç‚¹ {node_id} çš„ widget å€¼æ—¶å‡ºé”™: {widget_error}")
                            import traceback
                            traceback.print_exc()
            
            prompt[str(node_id)] = {
                "class_type": node["type"],
                "inputs": node_inputs
            }
        
        return prompt
    except Exception as e:
        print(f"[GroupExecutor] æ„å»º prompt å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {}

class GroupExecutorBackend:
    """åå°æ‰§è¡Œç®¡ç†å™¨"""
    
    def __init__(self):
        self.running_tasks = {}
        self.task_lock = threading.Lock()
        self.interrupted_prompts = set()  # è®°å½•è¢«ä¸­æ–­çš„ prompt_id
        self._setup_interrupt_handler()
    
    def _setup_interrupt_handler(self):
        """è®¾ç½®ä¸­æ–­å¤„ç†å™¨ï¼Œç›‘å¬ execution_interrupted æ¶ˆæ¯"""
        try:
            server = PromptServer.instance
            backend_instance = self
            
            # ä¿å­˜åŸå§‹çš„ send_sync æ–¹æ³•
            original_send_sync = server.send_sync
            
            def patched_send_sync(event, data, sid=None):
                # è°ƒç”¨åŸå§‹æ–¹æ³•
                original_send_sync(event, data, sid)
                
                # ç›‘å¬ execution_interrupted äº‹ä»¶
                if event == "execution_interrupted":
                    prompt_id = data.get("prompt_id")
                    if prompt_id:
                        backend_instance.interrupted_prompts.add(prompt_id)
                        # å–æ¶ˆæ‰€æœ‰åå°ä»»åŠ¡
                        backend_instance._cancel_all_on_interrupt()
            
            server.send_sync = patched_send_sync
        except Exception as e:
            print(f"[GroupExecutor] è®¾ç½®ä¸­æ–­ç›‘å¬å™¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def _cancel_all_on_interrupt(self):
        """å“åº”å…¨å±€ä¸­æ–­ï¼Œå–æ¶ˆæ‰€æœ‰æ­£åœ¨è¿è¡Œçš„åå°ä»»åŠ¡"""
        with self.task_lock:
            for node_id, task_info in list(self.running_tasks.items()):
                if task_info.get("status") == "running" and not task_info.get("cancel"):
                    task_info["cancel"] = True
    
    def execute_in_background(self, node_id, execution_list, workflow):
        """å¯åŠ¨åå°æ‰§è¡Œçº¿ç¨‹"""
        with self.task_lock:
            if node_id in self.running_tasks and self.running_tasks[node_id].get("status") == "running":
                return False
            
            thread = threading.Thread(
                target=self._execute_task,
                args=(node_id, execution_list, workflow),
                daemon=True
            )
            thread.start()
            
            self.running_tasks[node_id] = {
                "thread": thread,
                "status": "running",
                "cancel": False
            }
            return True
    
    def cancel_task(self, node_id):
        """å–æ¶ˆä»»åŠ¡"""
        with self.task_lock:
            if node_id in self.running_tasks:
                self.running_tasks[node_id]["cancel"] = True
                
                # ä¸­æ–­å½“å‰æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡
                try:
                    server = PromptServer.instance
                    server.send_sync("interrupt", {})
                except Exception as e:
                    print(f"[GroupExecutor] å‘é€ä¸­æ–­ä¿¡å·å¤±è´¥: {e}")
                
                return True
            return False
    
    def _execute_task(self, node_id, execution_list, workflow):
        """åå°æ‰§è¡Œä»»åŠ¡çš„æ ¸å¿ƒé€»è¾‘"""
        try:
            for execution in execution_list:
                # æ£€æŸ¥å–æ¶ˆæ ‡å¿—
                if self.running_tasks.get(node_id, {}).get("cancel"):
                    print(f"[GroupExecutor] ä»»åŠ¡è¢«å–æ¶ˆ")
                    break
                
                group_name = execution.get("group_name", "")
                repeat_count = int(execution.get("repeat_count", 1))
                delay_seconds = float(execution.get("delay_seconds", 0))
                
                # å¤„ç†å»¶è¿Ÿ
                if group_name == "__delay__":
                    if delay_seconds > 0 and not self.running_tasks.get(node_id, {}).get("cancel"):
                        # åˆ†æ®µå»¶è¿Ÿï¼Œä»¥ä¾¿èƒ½å¿«é€Ÿå“åº”å–æ¶ˆ
                        delay_steps = int(delay_seconds * 2)  # æ¯ 0.5 ç§’æ£€æŸ¥ä¸€æ¬¡
                        for _ in range(delay_steps):
                            if self.running_tasks.get(node_id, {}).get("cancel"):
                                break
                            time.sleep(0.5)
                    continue
                
                if not group_name:
                    continue
                
                # æŸ¥æ‰¾ç»„
                groups = workflow.get("groups", [])
                group = next((g for g in groups if g.get("title") == group_name), None)
                
                if not group:
                    print(f"[GroupExecutor] æœªæ‰¾åˆ°ç»„: {group_name}")
                    continue
                
                # è·å–ç»„å†…èŠ‚ç‚¹
                all_nodes = workflow.get("nodes", [])
                nodes_in_group = [n for n in all_nodes if is_node_in_group(n, group)]
                
                # ç­›é€‰è¾“å‡ºèŠ‚ç‚¹
                output_nodes = [n for n in nodes_in_group if is_output_node(n.get("type", ""))]
                
                if not output_nodes:
                    print(f"[GroupExecutor] ç»„ '{group_name}' ä¸­æ²¡æœ‰è¾“å‡ºèŠ‚ç‚¹")
                    continue
                
                # æ‰§è¡Œ repeat_count æ¬¡
                for i in range(repeat_count):
                    # æ£€æŸ¥å–æ¶ˆæ ‡å¿—
                    if self.running_tasks.get(node_id, {}).get("cancel"):
                        break
                    
                    if repeat_count > 1:
                        print(f"[GroupExecutor] æ‰§è¡Œç»„ '{group_name}' ({i+1}/{repeat_count})")
                    
                    # æ„å»º prompt
                    output_ids = [n["id"] for n in output_nodes]
                    prompt = build_prompt_for_nodes(workflow, output_ids)
                    
                    if not prompt:
                        print(f"[GroupExecutor] æ„å»º prompt å¤±è´¥")
                        continue
                    
                    # å¤„ç†éšæœºç§å­ï¼šä¸ºæ¯ä¸ªæœ‰ seed å‚æ•°çš„èŠ‚ç‚¹ç”Ÿæˆæ–°çš„éšæœºå€¼
                    import random
                    for node_id_str, node_data in prompt.items():
                        if "seed" in node_data.get("inputs", {}):
                            new_seed = random.randint(0, 0xffffffffffffffff)
                            prompt[node_id_str]["inputs"]["seed"] = new_seed
                    
                    # æäº¤åˆ°é˜Ÿåˆ—
                    prompt_id = self._queue_prompt(prompt)
                    
                    if prompt_id:
                        # ç­‰å¾…æ‰§è¡Œå®Œæˆï¼ˆè¿”å›æ˜¯å¦æ£€æµ‹åˆ°ä¸­æ–­ï¼‰
                        was_interrupted = self._wait_for_completion(prompt_id, node_id)
                        
                        # å¦‚æœç­‰å¾…æœŸé—´æ£€æµ‹åˆ°ä¸­æ–­ï¼Œç«‹å³é€€å‡º
                        if was_interrupted:
                            break
                    else:
                        print(f"[GroupExecutor] æäº¤ prompt å¤±è´¥")
                    
                    # å»¶è¿Ÿï¼ˆæ”¯æŒä¸­æ–­ï¼‰
                    if delay_seconds > 0 and i < repeat_count - 1:
                        if not self.running_tasks.get(node_id, {}).get("cancel"):
                            # åˆ†æ®µå»¶è¿Ÿï¼Œä»¥ä¾¿èƒ½å¿«é€Ÿå“åº”å–æ¶ˆ
                            delay_steps = int(delay_seconds * 2)  # æ¯ 0.5 ç§’æ£€æŸ¥ä¸€æ¬¡
                            for _ in range(delay_steps):
                                if self.running_tasks.get(node_id, {}).get("cancel"):
                                    break
                                time.sleep(0.5)
            
            if self.running_tasks.get(node_id, {}).get("cancel"):
                print(f"[GroupExecutor] ä»»åŠ¡å·²å–æ¶ˆ")
            else:
                print(f"[GroupExecutor] ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
            
        except Exception as e:
            print(f"[GroupExecutor] åå°æ‰§è¡Œå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
        finally:
            with self.task_lock:
                if node_id in self.running_tasks:
                    was_cancelled = self.running_tasks[node_id].get("cancel", False)
                    self.running_tasks[node_id]["status"] = "cancelled" if was_cancelled else "completed"
    
    def _queue_prompt(self, prompt):
        """æäº¤ prompt åˆ°é˜Ÿåˆ—"""
        try:
            server = PromptServer.instance
            prompt_id = str(uuid.uuid4())
            
            # éªŒè¯ promptï¼ˆvalidate_prompt æ˜¯å¼‚æ­¥å‡½æ•°ï¼Œéœ€è¦åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œï¼‰
            try:
                loop = server.loop
                # åœ¨äº‹ä»¶å¾ªç¯ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
                valid = asyncio.run_coroutine_threadsafe(
                    execution.validate_prompt(prompt_id, prompt, None),
                    loop
                ).result(timeout=30)
            except Exception as validate_error:
                print(f"[GroupExecutor] Prompt éªŒè¯å‡ºé”™: {validate_error}")
                import traceback
                traceback.print_exc()
                return None
            
            if not valid[0]:
                print(f"[GroupExecutor] Prompt éªŒè¯å¤±è´¥: {valid[1]}")
                return None
            
            # æäº¤åˆ°é˜Ÿåˆ—
            number = server.number
            server.number += 1
            
            # è·å–è¾“å‡ºèŠ‚ç‚¹åˆ—è¡¨
            outputs_to_execute = list(valid[2])
            
            server.prompt_queue.put((number, prompt_id, prompt, {}, outputs_to_execute))
            
            return prompt_id
            
        except Exception as e:
            print(f"[GroupExecutor] æäº¤é˜Ÿåˆ—å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _wait_for_completion(self, prompt_id, node_id):
        """ç­‰å¾… prompt æ‰§è¡Œå®Œæˆï¼ŒåŒæ—¶å“åº”å–æ¶ˆè¯·æ±‚
        è¿”å›: True å¦‚æœæ£€æµ‹åˆ°ä¸­æ–­ï¼ŒFalse æ­£å¸¸å®Œæˆ
        """
        try:
            server = PromptServer.instance
            
            while True:
                # æ£€æŸ¥è¿™ä¸ª prompt æ˜¯å¦è¢«ä¸­æ–­
                if prompt_id in self.interrupted_prompts:
                    # è®¾ç½®ä»»åŠ¡å–æ¶ˆæ ‡å¿—
                    with self.task_lock:
                        if node_id in self.running_tasks:
                            self.running_tasks[node_id]["cancel"] = True
                    # ä»ä¸­æ–­é›†åˆä¸­ç§»é™¤
                    self.interrupted_prompts.discard(prompt_id)
                    return True  # è¿”å›ä¸­æ–­çŠ¶æ€
                
                # æ£€æŸ¥æ˜¯å¦è¢«å–æ¶ˆ
                if self.running_tasks.get(node_id, {}).get("cancel"):
                    # ä»é˜Ÿåˆ—ä¸­åˆ é™¤è¿™ä¸ª promptï¼ˆå¦‚æœè¿˜åœ¨é˜Ÿåˆ—ä¸­ï¼‰
                    try:
                        def should_delete(item):
                            return len(item) >= 2 and item[1] == prompt_id
                        server.prompt_queue.delete_queue_item(should_delete)
                    except Exception as del_error:
                        print(f"[GroupExecutor] åˆ é™¤é˜Ÿåˆ—é¡¹æ—¶å‡ºé”™: {del_error}")
                    return True  # è¿”å›ä¸­æ–­çŠ¶æ€
                
                # æ£€æŸ¥æ˜¯å¦åœ¨å†å²è®°å½•ä¸­ï¼ˆè¡¨ç¤ºå·²å®Œæˆï¼‰
                if prompt_id in server.prompt_queue.history:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å› ä¸ºä¸­æ–­è€Œå®Œæˆçš„
                    if prompt_id in self.interrupted_prompts:
                        self.interrupted_prompts.discard(prompt_id)
                        return True
                    return False  # æ­£å¸¸å®Œæˆ
                
                # æ£€æŸ¥æ˜¯å¦è¿˜åœ¨é˜Ÿåˆ—ä¸­
                running, pending = server.prompt_queue.get_current_queue()
                
                in_queue = False
                for item in running:
                    if len(item) >= 2 and item[1] == prompt_id:
                        in_queue = True
                        break
                
                if not in_queue:
                    for item in pending:
                        if len(item) >= 2 and item[1] == prompt_id:
                            in_queue = True
                            break
                
                if not in_queue and prompt_id not in server.prompt_queue.history:
                    # å¯èƒ½å·²ç»æ‰§è¡Œå®Œæˆä½†è¿˜æ²¡æ›´æ–°å†å²è®°å½•ï¼Œå†ç­‰ä¸€ä¼š
                    time.sleep(0.5)
                    # å†æ¬¡æ£€æŸ¥
                    if prompt_id in server.prompt_queue.history:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯å› ä¸ºä¸­æ–­å®Œæˆçš„
                        if prompt_id in self.interrupted_prompts:
                            self.interrupted_prompts.discard(prompt_id)
                            return True
                        return False
                    if not in_queue:
                        return False
                
                time.sleep(0.5)
                
        except Exception as e:
            print(f"[GroupExecutor] ç­‰å¾…æ‰§è¡Œå®Œæˆæ—¶å‡ºé”™: {e}")
            return False

# å…¨å±€åå°æ‰§è¡Œå™¨å®ä¾‹
_backend_executor = GroupExecutorBackend()

# ============ èŠ‚ç‚¹å®šä¹‰ ============

class GroupExecutorSingle:
    """å•ç»„æ‰§è¡ŒèŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "group_name": ("STRING", {"default": "", "multiline": False}),
                "repeat_count": ("INT", {"default": 1, "min": 1, "max": 100, "step": 1}),
                "delay_seconds": ("FLOAT", {"default": 0.0, "min": 0.0, "max": 60.0, "step": 0.1}),
            },
            "optional": {
                "signal": ("SIGNAL",),
            },
            "hidden": {
                "unique_id": "UNIQUE_ID"
            }
        }
    
    RETURN_TYPES = ("SIGNAL",)
    FUNCTION = "execute_group"
    CATEGORY = CATEGORY_TYPE

    def execute_group(self, group_name, repeat_count, delay_seconds, signal=None, unique_id=None):
        try:
            current_execution = {
                "group_name": group_name,
                "repeat_count": repeat_count,
                "delay_seconds": delay_seconds
            }
            
            # å¦‚æœæœ‰ä¿¡å·è¾“å…¥
            if signal is not None:
                if isinstance(signal, list):
                    signal.append(current_execution)
                    return (signal,)
                else:
                    result = [signal, current_execution]
                    return (result,)

            return (current_execution,)

        except Exception as e:
            print(f"[GroupExecutorSingle {unique_id}] é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return ({"error": str(e)},)

class GroupExecutorSender:
    """æ‰§è¡Œä¿¡å·å‘é€èŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "signal": ("SIGNAL",),
                "execution_mode": (["å‰ç«¯æ‰§è¡Œ", "åå°æ‰§è¡Œ"], {"default": "åå°æ‰§è¡Œ"}),
            },
            "hidden": {
                "unique_id": "UNIQUE_ID",
                "prompt": "PROMPT",
                "extra_pnginfo": "EXTRA_PNGINFO"
            }
        }
    
    RETURN_TYPES = () 
    FUNCTION = "execute"
    CATEGORY = CATEGORY_TYPE
    OUTPUT_NODE = True

    def execute(self, signal, execution_mode, unique_id=None, prompt=None, extra_pnginfo=None):
        try:
            if not signal:
                raise ValueError("æ²¡æœ‰æ”¶åˆ°æ‰§è¡Œä¿¡å·")

            execution_list = signal if isinstance(signal, list) else [signal]

            if execution_mode == "åå°æ‰§è¡Œ":
                # è·å–å®Œæ•´çš„ workflow
                workflow = None
                if extra_pnginfo and "workflow" in extra_pnginfo:
                    workflow = extra_pnginfo["workflow"]
                else:
                    print(f"[GroupExecutor] è­¦å‘Šï¼šæ— æ³•è·å– workflowï¼Œé™çº§ä¸ºå‰ç«¯æ‰§è¡Œ")
                    # é™çº§ä¸ºå‰ç«¯æ‰§è¡Œ
                    PromptServer.instance.send_sync(
                        "execute_group_list", {
                            "node_id": unique_id,
                            "execution_list": execution_list
                        }
                    )
                    return ()
                
                # å¯åŠ¨åå°æ‰§è¡Œ
                _backend_executor.execute_in_background(
                    unique_id, 
                    execution_list, 
                    workflow
                )
                
            else:
                # å‰ç«¯æ‰§è¡Œæ¨¡å¼ï¼ˆåŸæœ‰æ–¹å¼ï¼‰
                PromptServer.instance.send_sync(
                    "execute_group_list", {
                        "node_id": unique_id,
                        "execution_list": execution_list
                    }
                )
            
            return ()  

        except Exception as e:
            print(f"[GroupExecutor] æ‰§è¡Œé”™è¯¯: {str(e)}")
            import traceback
            traceback.print_exc()
            return ()

class GroupExecutorRepeater:
    """æ‰§è¡Œåˆ—è¡¨é‡å¤å¤„ç†èŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "signal": ("SIGNAL",),
                "repeat_count": ("INT", {
                    "default": 1, 
                    "min": 1, 
                    "max": 100,
                    "step": 1
                }),
                "group_delay": ("FLOAT", {
                    "default": 0.0,
                    "min": 0.0,
                    "max": 300.0,
                    "step": 0.1
                }),
            },
        }
    
    RETURN_TYPES = ("SIGNAL",)
    FUNCTION = "repeat"
    CATEGORY = CATEGORY_TYPE

    def repeat(self, signal, repeat_count, group_delay):
        try:
            if not signal:
                raise ValueError("æ²¡æœ‰æ”¶åˆ°æ‰§è¡Œä¿¡å·")

            execution_list = signal if isinstance(signal, list) else [signal]

            repeated_list = []
            for i in range(repeat_count):

                repeated_list.extend(execution_list)

                if i < repeat_count - 1:

                    repeated_list.append({
                        "group_name": "__delay__",
                        "repeat_count": 1,
                        "delay_seconds": group_delay
                    })
            
            return (repeated_list,)

        except Exception as e:
            print(f"é‡å¤å¤„ç†é”™è¯¯: {str(e)}")
            return ([],)
        

CONFIG_DIR = os.path.join(os.path.dirname(os.path.realpath(__file__)), "group_configs")
os.makedirs(CONFIG_DIR, exist_ok=True)

routes = PromptServer.instance.routes
@routes.get("/group_executor/configs")
async def get_configs(request):
    try:

        configs = []
        for filename in os.listdir(CONFIG_DIR):
            if filename.endswith('.json'):
                configs.append({
                    "name": filename[:-5]
                })
        return web.json_response({"status": "success", "configs": configs})
    except Exception as e:
        print(f"[GroupExecutor] è·å–é…ç½®å¤±è´¥: {str(e)}")
        return web.json_response({"status": "error", "message": str(e)}, status=500)

@routes.post("/group_executor/configs")
async def save_config(request):
    try:
        print("[GroupExecutor] æ”¶åˆ°ä¿å­˜é…ç½®è¯·æ±‚")
        data = await request.json()
        config_name = data.get('name')
        if not config_name:
            return web.json_response({"status": "error", "message": "é…ç½®åç§°ä¸èƒ½ä¸ºç©º"}, status=400)
            
        safe_name = "".join(c for c in config_name if c.isalnum() or c in (' ', '-', '_'))
        filename = os.path.join(CONFIG_DIR, f"{safe_name}.json")
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
        print(f"[GroupExecutor] é…ç½®å·²ä¿å­˜: {filename}")
        return web.json_response({"status": "success"})
    except json.JSONDecodeError as e:
        print(f"[GroupExecutor] JSONè§£æé”™è¯¯: {str(e)}")
        return web.json_response({"status": "error", "message": f"JSONæ ¼å¼é”™è¯¯: {str(e)}"}, status=400)
    except Exception as e:
        print(f"[GroupExecutor] ä¿å­˜é…ç½®å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return web.json_response({"status": "error", "message": str(e)}, status=500)

@routes.get('/group_executor/configs/{name}')
async def get_config(request):
    try:
        config_name = request.match_info.get('name')
        if not config_name:
            return web.json_response({"error": "é…ç½®åç§°ä¸èƒ½ä¸ºç©º"}, status=400)
            
        filename = os.path.join(CONFIG_DIR, f"{config_name}.json")
        if not os.path.exists(filename):
            return web.json_response({"error": "é…ç½®ä¸å­˜åœ¨"}, status=404)
            
        with open(filename, 'r', encoding='utf-8') as f:
            config = json.load(f)
            
        return web.json_response(config)
    except Exception as e:
        return web.json_response({"error": str(e)}, status=500)

@routes.delete('/group_executor/configs/{name}')
async def delete_config(request):
    try:
        config_name = request.match_info.get('name')
        if not config_name:
            return web.json_response({"error": "é…ç½®åç§°ä¸èƒ½ä¸ºç©º"}, status=400)
            
        filename = os.path.join(CONFIG_DIR, f"{config_name}.json")
        if not os.path.exists(filename):
            return web.json_response({"error": "é…ç½®ä¸å­˜åœ¨"}, status=404)
            
        os.remove(filename)
        return web.json_response({"status": "success"})
    except Exception as e:
        return web.json_response({"error": str(e)}, status=500)